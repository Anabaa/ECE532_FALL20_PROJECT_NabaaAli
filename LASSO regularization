
## iterative soft-thresholding for LASSO 
def ista_solve_hot( A, d, la_array ):
    # ista_solve_hot: Iterative soft-thresholding for multiple values of
    # lambda with hot start for each case - the converged value for the previous
    # value of lambda is used as an initial condition for the current lambda.
    # this function solves the minimization problem
    # Minimize |Ax-d|_2^2 + lambda*|x|_1 (Lasso regression)
    # using iterative soft-thresholding.
    max_iter = 10**4
    tol = 10**(-3)
    tau = 1/np.linalg.norm(A,2)**2
    n = A.shape[1]
    w = np.zeros((n,1))
    num_lam = len(la_array)
    X = np.zeros((n, num_lam))
    for i, each_lambda in enumerate(la_array):
        for j in range(max_iter):
            z = w - tau*(A.T@(A@w-d))
            w_old = w
            w = np.sign(z) * np.clip(np.abs(z)-tau*each_lambda/2, 0, np.inf)
            X[:, i:i+1] = w
            if np.linalg.norm(w - w_old) < tol:
                break
    return X
## Create the regularizer array for LASSO 
lam_array=[1e-7,1e-6,1e-4,1e-2,0.1,2]
lam_array=np.hstack((lam_array,np.logspace(0,6,num=40)))
## Split the data into 7  sets 
setindices=np.asarray([[0,10000],[10000,20000],[20000,30000],[30000,40000],[40000,50000],[50000,60000],[60000,rows_x]])
holdoutindices=np.asarray([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,0]])
cases_num=7
lam_num=lam_array.shape[0]
index=np.asarray(range(rows_x))
err_l1=np.zeros(cases_num)
res_l1=np.zeros(cases_num)
## Iterate over the 7 sets to find the optimum values of lambda and w 
for j in range(cases_num):
    s1_indx=index[setindices[holdoutindices[j,0],0]:setindices[holdoutindices[j,0],1]]
    s2_indx=index[setindices[holdoutindices[j,1],0]:setindices[holdoutindices[j,1],1]]
    inter_indx=np.setdiff1d(np.setdiff1d(index,s1_indx),s2_indx);
    x_test_1 =X_m[s1_indx,:]
    y_test_1=y_filter[s1_indx,:]
    x_test_2=X_m[s2_indx,:]
    y_test_2=y_filter[s2_indx,:]
    x_train=X_m[inter_indx,:]
    y_train=y_filter[inter_indx,:]
    W=ista_solve_hot(x_train,y_train,lam_array)
    err_1=np.zeros(lam_num)
    for i in range(lam_num): 
        pred_1=np.sign(x_test_1@W[:,i:i+1])
        err_1[i]=np.mean(pred_1!=y_test_1)
    min_indx=np.argmin(err_1)
    err_l1[j]=np.mean(np.sign(x_test_2@W[:,min_indx:min_indx+1])!=y_test_2)
    res_l1[j]=np.linalg.norm(x_test_2@W[:,min_indx:min_indx+1]-y_test_2)
## find the error rate% and the residual ||Xw-y||^(2) for LASSO 
err_tot_l1=np.mean(err_l1)
res_tot_l1=np.mean(res_l1)
print('The optimum lambda for the last set is:',lam_array[min_indx])
print('The optimum weights vector for the last set  is w =',W[:,min_indx:min_indx+1])
print("err_tot_l1 =",err_tot_l1)
print("res_tot_l1 =",res_tot_l1)
